# ðŸ§  Visual Question Answering Model

A deep learning project that combines **Computer Vision** and **Natural Language Processing** to answer questions about images.  
This repository demonstrates how to build and run a **Visual Question Answering (VQA)** system using pre-trained transformer models.

---

## ðŸš€ Project Overview

Visual Question Answering (VQA) is an AI task where the model takes both an **image** and a **question** in natural language as input, and produces an **answer** in text form.  
This repository shows how to:

- Process visual and textual inputs together
- Use transformer-based VQA models
- Generate accurate answers using open-source pretrained models

---

## ðŸ§© Features

- Image and text joint processing
- Hugging Face Transformer-based architecture
- Fully runnable on **Google Colab**
- No Google Cloud credentials required
- Simple and beginner-friendly structure
